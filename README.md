# Kaggle Competition - Jigsaw Unintended Bias in Toxicity Classification
## Detect toxicity across a diverse range of conversations

Project No. 2.0 for the Upskill IM Cohort Program for Machine Learning Engineers.

</br>

## Description

In this competition, the challenge is to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. The data comes from The Conversation AI team, a research initiative founded by Jigsaw and Google (both part of Alphabet).

## Getting Started

### Dependencies

* [Pre-trained word vectors from Stanford](https://nlp.stanford.edu/projects/glove/)


### Executing program

* The notebook's total runtime was 1.15 hours with GPU on Kaggle.

</br>

## Author

Maksudur Rahman

</br>

## Version History

* 0.1
    * Initial Release

## License

This project is licensed under the Apache 2.0 License.